"""
è¿è¡Œé¢è¯•è¯„ä¼°ç³»ç»Ÿï¼ˆä½¿ç”¨è¯­éŸ³è¯†åˆ«ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    python -m voice_interaction.examples.run_interview_assessment_voice
"""

from voice_interaction.pipeline.assessment_pipeline import InterviewAssessmentPipeline
from voice_interaction.pipeline.tts_pipeline import TTSPipeline
from voice_interaction.pipeline.speech_recognition_pipeline import SpeechRecognitionPipeline
from voice_interaction.pipeline.voice_pipeline import VoiceProcessingPipeline
import numpy as np


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œé¢è¯•è¯„ä¼°"""
    print("=" * 60)
    print("JingXin é¢è¯•è¯„ä¼°ç³»ç»Ÿï¼ˆè¯­éŸ³è¯†åˆ«ç‰ˆï¼‰")
    print("=" * 60)
    print("â„¹ï¸  ç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«æ‚¨çš„è¯­éŸ³å›ç­”")
    print("ğŸ›‘ è¾“å…¥ 'quit' é€€å‡ºç¨‹åº\n")

    # åˆå§‹åŒ–ç»„ä»¶
    interview = InterviewAssessmentPipeline()
    tts = TTSPipeline()
    recognizer = SpeechRecognitionPipeline()
    voice_processor = VoiceProcessingPipeline()

    # å¼€å§‹é¢è¯•
    while True:
        question = interview.get_next_question()
        if not question:
            print("\n" + "=" * 60)
            print("é¢è¯•å·²ç»“æŸï¼æ­£åœ¨ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...")
            print("=" * 60)
            break

        # æ˜¾ç¤ºé—®é¢˜
        print(f"\né—®é¢˜: {question}")

        # è¯­éŸ³æ’­æŠ¥é—®é¢˜
        if tts.is_available():
            tts.speak(question)

        # è·å–ç”¨æˆ·å›ç­”ï¼ˆä½¿ç”¨è¯­éŸ³è¯†åˆ«ï¼‰
        print("\nğŸ¤ è¯·å›ç­”ï¼ˆè¯´å®Œåç¨ä½œåœé¡¿å³å¯ï¼‰...")
        result, audio_data = recognizer.listen_for_speech(
            timeout=30,
            pause_threshold=1.2
        )
        answer = result.text

        if not answer:
            print("\nâŒ æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³ï¼Œè¯·é‡æ–°å›ç­”")
            continue

        # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
        print(f"âœ“ è¯†åˆ«ç»“æœ: {answer}")

        # åˆ†æè¯­éŸ³ç‰¹å¾
        # ç¡®ä¿éŸ³é¢‘æ•°æ®æ ¼å¼æ­£ç¡®
        if len(audio_data) > 0:
            # å°†éŸ³é¢‘æ•°æ®è½¬æ¢å› int16 æ ¼å¼
            audio_int16 = (audio_data * 32768.0).astype(np.int16)
            # å†è½¬æ¢å› float32ï¼Œä½†ä½¿ç”¨æ­£ç¡®çš„å½’ä¸€åŒ–
            audio_normalized = audio_int16.astype(np.float32) / 32768.0
            voice_result = voice_processor.process_audio(audio_normalized)
            features = voice_result.get("features")
            analysis = voice_result.get("analysis")
        else:
            features = None
            analysis = None

        # è®°å½•å›ç­”ï¼ˆåŒ…å«è¯­éŸ³ç‰¹å¾å’Œåˆ†æï¼‰
        interview.add_qa_pair(
            question=question,
            answer=answer,
            prosody_features=features,
            prosody_analysis=analysis
        )

    # è·å–è¯„ä¼°ç»“æœ
    print("\n" + "=" * 60)
    print("è¯„ä¼°ç»“æœ")
    print("=" * 60)
    result = interview.get_comprehensive_evaluation()
    print(result)

    # ä¿å­˜æ—¥å¿—
    log_path = interview.save_log()
    print(f"\nâœ“ è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜è‡³: {log_path}")


if __name__ == "__main__":
    main()
