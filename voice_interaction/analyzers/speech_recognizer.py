import os
import json
import queue
import logging
import numpy as np
from typing import Tuple
from vosk import Model, KaldiRecognizer
import sounddevice as sd

logger = logging.getLogger(__name__)

# è‡ªåŠ¨å®šä½æ¨¡å‹è·¯å¾„
ROOT_DIR = os.path.dirname(
    os.path.dirname(
        os.path.dirname(os.path.abspath(__file__))
    )
)
MODEL_PATH = os.path.join(ROOT_DIR, "vosk-model-small-cn-0.22")

if not os.path.exists(MODEL_PATH):
    raise RuntimeError(f"âŒ Vosk æ¨¡å‹æœªæ‰¾åˆ°: {os.path.abspath(MODEL_PATH)}")


class SpeechRecognizer:
    def __init__(self):
        self.sample_rate = 16000
        logger.info("æ­£åœ¨åŠ è½½ Vosk æ¨¡å‹...")
        self.model = Model(MODEL_PATH)
        logger.info("âœ… Vosk æ¨¡å‹åŠ è½½å®Œæˆ")

    def listen_for_speech(self, timeout: int = 30) -> Tuple[str, np.ndarray]:
        q = queue.Queue()
        audio_chunks = []
        recognized_text = ""  # å­˜å‚¨æœ€ç»ˆè¯†åˆ«æ–‡æœ¬

        def callback(indata, frames, time, status):
            if status:
                logger.warning(f"å½•éŸ³çŠ¶æ€: {status}")
            if not isinstance(indata, bytes):
                indata = bytes(indata)
            q.put(indata)
            audio_chunks.append(indata)

        print("ğŸ¤ è¯·å›ç­”ï¼ˆè¯´å®Œåç¨ä½œåœé¡¿å³å¯ï¼‰...")

        try:
            with sd.RawInputStream(
                    samplerate=self.sample_rate,
                    blocksize=8000,
                    dtype='int16',
                    channels=1,
                    callback=callback
            ):
                recognizer = KaldiRecognizer(self.model, self.sample_rate)
                silence_count = 0
                total_time = 0.0

                while True:
                    try:
                        data = q.get(timeout=1.0)
                    except queue.Empty:
                        silence_count += 10
                        total_time += 1.0
                        if total_time > timeout:
                            break
                        continue

                    if not isinstance(data, bytes):
                        data = bytes(data)

                    total_time += 0.1

                    # å…³é”®ï¼šç´¯ç§¯æ‰€æœ‰è¯†åˆ«ç»“æœ
                    if recognizer.AcceptWaveform(data):
                        res = json.loads(recognizer.Result())
                        text_chunk = res.get("text", "").strip()
                        if text_chunk:
                            recognized_text += text_chunk + " "
                            silence_count = 0
                            print(f"ğŸ“ ä½ è¯´çš„æ˜¯: '{text_chunk}'")
                    else:
                        partial = json.loads(recognizer.PartialResult()).get("partial", "")
                        if not partial:
                            silence_count += 1
                        else:
                            silence_count = 0

                    if silence_count > 20 or total_time > timeout:
                        break

                # ä¸è¦å†è°ƒç”¨ FinalResult()ï¼
                recognized_text = recognized_text.strip()

                # åˆå¹¶éŸ³é¢‘
                if audio_chunks:
                    full_bytes = b''.join(audio_chunks)
                    audio_int16 = np.frombuffer(full_bytes, dtype=np.int16)
                    audio_float32 = audio_int16.astype(np.float32) / 32768.0
                else:
                    audio_float32 = np.array([])

                if not recognized_text:
                    print("ğŸ“ æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³")
                else:
                    print(f"âœ… æœ€ç»ˆè¯†åˆ«ç»“æœ: '{recognized_text}'")

                return recognized_text, audio_float32

        except Exception as e:
            logger.error(f"å½•éŸ³æˆ–è¯†åˆ«å¼‚å¸¸: {e}")
            print(f"âŒ è¯­éŸ³äº¤äº’å¤±è´¥: {e}")
            return "", np.array([])