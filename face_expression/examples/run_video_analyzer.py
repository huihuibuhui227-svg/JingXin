import cv2
import time
import csv
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# ä½¿ç”¨ç»å¯¹å¯¼å…¥
try:
    from face_expression.analyzers.face_au_analyzer import FaceAUAnalyzer
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£…å¿…è¦çš„ä¾èµ–: pip install opencv-python-headless mediapipe")
    exit(1)

# å°è¯•å¯¼å…¥ MediaPipeï¼ˆå¯é€‰ï¼‰
mp_drawing = None
mp_drawing_styles = None
mp_face_mesh = None
try:
    import mediapipe as mp
    mp_drawing = mp.solutions.drawing_utils
    mp_drawing_styles = mp.solutions.drawing_styles
    mp_face_mesh = mp.solutions.face_mesh
    print("âœ“ MediaPipe å·²åŠ è½½")
except ImportError as e:
    print(f"âš ï¸ MediaPipe å¯¼å…¥å¤±è´¥: {e}")
    print("å°†è¿è¡Œåœ¨æ—  MediaPipe æ¨¡å¼ä¸‹ï¼ˆä»…æ˜¾ç¤ºåŸºç¡€ä¿¡æ¯ï¼‰")


def main():
    """ä¸»å‡½æ•°ï¼šå®æ—¶è§†é¢‘æµAUåˆ†æ"""
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    actual_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    print(f"æ‘„åƒå¤´å®é™…åˆ†è¾¨ç‡: {actual_w} x {actual_h}")

    if actual_w < 640 or actual_h < 480:
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        print("âš ï¸ åˆ†è¾¨ç‡è¿‡ä½ï¼Œå·²å›é€€åˆ° 640x480")

    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return

    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
    try:
        analyzer = FaceAUAnalyzer(fps=fps)
    except Exception as e:
        print(f"âŒ åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
    project_root = Path(__file__).parent.parent.parent
    log_dir = project_root / 'data' / 'logs'
    log_dir.mkdir(parents=True, exist_ok=True)
    log_path = log_dir / "face_au_log.csv"

    fieldnames = [
        "timestamp", "focus_score", "blink_rate_per_min", "au4_frown", "au12_eyebrow_raise",
        "au12_smile", "au9_nose_wrinkle", "au15_mouth_down", "au25_mouth_open", "eye_closed_sec", "emotion"
    ]

    with open(log_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()

    print("æŒ‰ 'q' é€€å‡ºã€‚æ•°æ®å°†è®°å½• 10 åˆ†é’Ÿ...")
    start_time = time.time()
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        features, results, emotion = analyzer.process_frame(frame_rgb)

        annotated_frame = frame.copy()
        if results and results.multi_face_landmarks and mp_drawing is not None:
            for face_landmarks in results.multi_face_landmarks:
                mp_drawing.draw_landmarks(
                    image=annotated_frame,
                    landmark_list=face_landmarks,
                    connections=mp_face_mesh.FACEMESH_CONTOURS,
                    landmark_drawing_spec=None,
                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()
                )

        # åœ¨è§†é¢‘çª—å£ä¸Šæ˜¾ç¤º AU å€¼ï¼ˆè‹±æ–‡+æ•°å­—ï¼‰
        if features:
            lines = [
                f"Focus: {features['focus_score']}",
                f"Blink: {features['blink_rate_per_min']}/min",
                f"AU4_Frown: {features['au4_frown']}",
                f"AU12_Raise: {features['au12_eyebrow_raise']}",
                f"AU12_Smile: {features['au12_smile']}",
                f"AU9_Wrinkle: {features['au9_nose_wrinkle']}",
                f"AU15_Down: {features['au15_mouth_down']}",
                f"AU25_Open: {features['au25_mouth_open']}",
                f"EyeClosed: {features['eye_closed_sec']}s"
            ]
            for i, line in enumerate(lines):
                cv2.putText(annotated_frame, line, (10, 30 + i * 25),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        cv2.imshow("Facial AU Analyzer (Press 'q' to quit)", annotated_frame)

        # åœ¨æ§åˆ¶å°å®æ—¶æ˜¾ç¤ºæƒ…ç»ª
        if emotion != "æ— äººè„¸":
            print(f"[{time.strftime('%H:%M:%S')}] å½“å‰æƒ…ç»ª: {emotion}")

        # å†™å…¥ CSV
        if features:
            features_copy = features.copy()  # é¿å…ä¿®æ”¹åŸå§‹å­—å…¸
            features_copy["emotion"] = emotion
            with open(log_path, 'a', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writerow(features_copy)

        # è¿è¡Œ 10 åˆ†é’Ÿåè‡ªåŠ¨é€€å‡º
        if time.time() - start_time > 600:  # 10 åˆ†é’Ÿ = 600 ç§’
            print("âœ… 10 åˆ†é’Ÿæ•°æ®é‡‡é›†å®Œæˆï¼Œæ­£åœ¨ä¿å­˜...")
            break

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    print(f"ğŸ“Š æ•°æ®å·²ä¿å­˜è‡³ {log_path}")


if __name__ == "__main__":
    main()